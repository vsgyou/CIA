import gradio as gr
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from collections import Counter
import ast
import os
import openai



# CSV ë¡œë“œ ë° ì „ì²˜ë¦¬

def load_csv(data_path):
    # df = pd.read_csv(os.path.join("data",data_path))
    df = pd.read_csv(data_path)
    df["satisfaction"] = df["rating"].apply(lambda x: np.mean(ast.literal_eval(x)) if pd.notna(x) else np.nan)
    df["rating"] = df["rating"].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])
    df["watched"] = df["watched"].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])
    df["feeling"] = df["feeling"].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])
    df["satisfaction"] = df["rating"].apply(lambda x: sum(x) / len(x) if x else None)

    def classify_satisfaction_level(row):
        if pd.isna(row["satisfaction"]):
            return "unknown"
        elif row["satisfaction"] >= 4.5:
            return "satisfied"
        elif row["satisfaction"] >= 4.0:
            return "neutral"
        else:
            return "unsatisfied"

    df["satisfaction_level"] = df.apply(classify_satisfaction_level, axis=1)

    policy_list = df["policy"].unique().tolist()
    return df, policy_list

def load_sim_csv(data_path):
    df = pd.read_csv(data_path)
    return df

# RQ1: ê° traitë³„ë¡œ ì •ì±… ë§Œì¡±ë„ ë° ì„ íƒë¥  ë¹„êµ
def plot_policy_by_trait(df, trait):
    filtered_df = df[df['rerank'] == 'Prefer']

    grouped = filtered_df.groupby([trait, "policy"]).satisfaction.mean().reset_index()
    baseline = grouped.groupby(trait)["satisfaction"].transform("mean")
    grouped["delta"] = grouped["satisfaction"] - baseline

    filtered_df["selected"] = filtered_df["rating"].apply(lambda x: len(x))
    filtered_df["select_rate"] = filtered_df["selected"] / 4
    rate_df = filtered_df.groupby([trait, "policy"])["select_rate"].mean().reset_index()

    violin_fig = px.violin(grouped, x="policy", y="delta", color=trait, box=True,
                           title=f"RQ1 Violin: ì •ì±…ë³„ {trait} delta ë¶„í¬")
    violin_fig.update_layout(margin=dict(t=40, l=0, r=0, b=0))

    scatter_fig = px.scatter(grouped.merge(rate_df, on=[trait, 'policy']),
        x="select_rate", y="satisfaction", color="policy", symbol=trait,
        title=f"RQ1 Scatter: {trait}ë³„ ì„ íƒë¥  vs ë§Œì¡±ë„")
    scatter_fig.update_layout(margin=dict(t=40, l=0, r=0, b=0))

    return violin_fig, scatter_fig

# RQ2: ê° traitë³„ ì •ì±…ê°„ Uplift ë¹„êµ
def plot_uplift_by_trait(df, trait):
    policy_list = df["policy"].unique()
    uplift_df = []
    for t_val in df[trait].unique():
        trait_df = df[(df["rerank"] == "Prefer") & (df[trait] == t_val)]
        avg = trait_df.groupby("policy")["satisfaction"].mean()
        for p1 in policy_list:
            for p2 in policy_list:
                if p1 != p2:
                    uplift_df.append({
                        trait: t_val,
                        "policy_pair": f"{p1} vs {p2}",
                        "uplift": avg.get(p1, 0) - avg.get(p2, 0)
                    })
    uplift_df = pd.DataFrame(uplift_df)

    bar_fig = px.bar(uplift_df, x=trait, y="uplift", color="policy_pair",
                     title=f"RQ2: {trait}ë³„ ì •ì±…ê°„ Uplift ë¹„êµ")
    bar_fig.update_layout(margin=dict(t=40, l=0, r=0, b=0))

    return bar_fig,

# RQ3: ì •ì±…ë³„ë¡œ ì„±ëŠ¥ì°¨ê°€ í° trait ê°’ ì°¾ê¸° (Radar Chartë§Œ ì‚¬ìš©)
def plot_policy_variation_radar(df):
    radar_data = []
    for policy in df["policy"].unique():
        variations = []
        for trait in ["activity", "conformity", "diversity"]:
            filtered = df[(df["rerank"] == "Prefer") & (df["policy"] == policy)]
            group = filtered.groupby(trait)["satisfaction"].mean()
            group = group[[v for v in group.index if v not in ["ì¤‘ê°„", "ê· í˜•í˜•"]]]
            if not group.empty:
                variation = group.max() - group.min()
                variations.append(variation)
            else:
                variations.append(0)
        radar_data.append({"policy": policy, "activity": variations[0], "conformity": variations[1], "diversity": variations[2]})

    radar_df = pd.DataFrame(radar_data)
    fig = go.Figure()
    for i, row in radar_df.iterrows():
        fig.add_trace(go.Scatterpolar(
            r=[row["activity"], row["conformity"], row["diversity"]],
            theta=["activity", "conformity", "diversity"],
            fill='toself',
            name=row["policy"]
        ))

    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0.0, max(radar_df[['activity','conformity','diversity']].max()) + 0.03])),
        title="RQ3 Radar: ì •ì±…ë³„ trait ë¯¼ê°ë„ í”„ë¡œíŒŒì¼",
        showlegend=True,
        margin=dict(t=40, l=0, r=0, b=0)
    )

    return fig
# ---------------------

RQ1_PROMPT = """
ë‹¹ì‹ ì€ ì¶”ì²œ ì‹œìŠ¤í…œê³¼ ì¸ê³¼ì¶”ë¡ ì— ëŠ¥ìˆ™í•œ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ í‘œëŠ” ë™ì¼í•œ ê³ ê°êµ°ì„ ì„¸ ê°€ì§€ íŠ¹ì„±(activity, conformity, diversity)ìœ¼ë¡œ ë‚˜ëˆˆ í›„,  
ì¶”ì²œì •ì±…ë³„ë¡œ ê³ ê°ì˜ ë°˜ì‘(ë§Œì¡±ë„, ì„ íƒë¥ )ì„ ì¸¡ì •í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ê° íŠ¹ì„±(activity, conformity, diversity)**ì— ëŒ€í•´,
   - ì–´ë–¤ ì¶”ì²œì •ì±…ì´ ê°€ì¥ ë†’ì€ ë§Œì¡±ë„/ì„ íƒë¥ ì„ ë³´ì˜€ëŠ”ì§€
   - íŠ¹ì„± ê°„ ë°˜ì‘ ì°¨ì´ê°€ ì–¼ë§ˆë‚˜ ëšœë ·í•œì§€

2. ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì •ì±…ë³„ë¡œ ì–´ë–¤ ê³ ê°êµ°ì— ì í•©í•œì§€ í•´ì„**í•´ì£¼ì„¸ìš”.

3. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì „ì²´ì ìœ¼ë¡œ ë´¤ì„ ë•Œ **ê°€ì¥ ë°˜ì‘ì´ ì¢‹ì•˜ë˜ ì •ì±…ì€ ë¬´ì—‡ì´ë©°, ì–´ë–¤ íŠ¹ì„±ê³¼ ì˜ ë§ì•˜ëŠ”ì§€ ì¢…í•©ì ìœ¼ë¡œ ìš”ì•½**í•´ ì£¼ì„¸ìš”.
"""

RQ2_PROMPT = """
ë‹¹ì‹ ì€ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ í•´ì„í•˜ëŠ” ì¸ê³¼ì¶”ë¡  ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ í‘œëŠ” ì„¸ ê°€ì§€ ê³ ê° íŠ¹ì„±(activity, conformity, diversity) ê°’ì— ë”°ë¼,  
ì •ì±… ê°„ ë§Œì¡±ë„ uplift(ì •ì±…1 - ì •ì±…2)ë¥¼ ë¹„êµí•œ ê²°ê³¼ì…ë‹ˆë‹¤.

ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ê° íŠ¹ì„±ë³„(activity, conformity, diversity)**ë¡œ ë´¤ì„ ë•Œ,  
   - ì–´ë–¤ ê³ ê°êµ°ì—ì„œ ì •ì±… ê°„ uplift ì°¨ì´ê°€ ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚¬ëŠ”ì§€
   - íŠ¹ì • íŠ¹ì„± ì¡°í•©ì—ì„œ ì¼ê´€ëœ ìš°ì„¸ ì •ì±…ì´ ìˆëŠ”ì§€

2. íŠ¹ì„±ì— ë”°ë¼ **ì •ì±… ì„ íƒì˜ ë°©í–¥ì„ ì–´ë–»ê²Œ ì„¤ì •í•  ìˆ˜ ìˆì„ì§€** ì „ëµì ìœ¼ë¡œ í•´ì„í•´ì£¼ì„¸ìš”.

3. ì „ì²´ì ìœ¼ë¡œ ì–´ë–¤ íŠ¹ì„±ì´ ì •ì±… ê°„ ì„±ê³¼ ì°¨ì´ë¥¼ í¬ê²Œ ë§Œë“¤ë©°, **ê³ ê° ë§ì¶¤í˜• ì •ì±… ì„ ì •ì˜ ê°€ëŠ¥ì„±**ì´ ìˆëŠ”ì§€ ìš”ì•½í•´ì£¼ì„¸ìš”.
"""

RQ3_PROMPT = """
ë‹¹ì‹ ì€ ì •ì±… ì„±ëŠ¥ì˜ ì°¨ì´ë¥¼ ê³ ê° íŠ¹ì„± ê´€ì ì—ì„œ í•´ì„í•˜ëŠ” ì¸ê³¼ì¶”ë¡  ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ê° ì¶”ì²œì •ì±…ì´ ê³ ê° íŠ¹ì„±(activity, conformity, diversity)ì— ëŒ€í•´  
ë§Œì¡±ë„ ê¸°ì¤€ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ë¯¼ê°í•˜ê²Œ ë°˜ì‘í–ˆëŠ”ì§€ë¥¼ ì‹œê°í™”í•œ ê²°ê³¼ì…ë‹ˆë‹¤ (Radar Chart ê¸°ë°˜).
ë¯¼ê°ë„ëŠ” íŠ¹ì„± ì°¨ì´ì— ë”°ë¥¸ ì„±ëŠ¥ì˜ í¸ì°¨ì…ë‹ˆë‹¤.

ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ê° íŠ¹ì„±(activity, conformity, diversity)**ì— ëŒ€í•´,  
   - ì–´ë–¤ ì •ì±…ì´ ê°€ì¥ ë¯¼ê°í•˜ê²Œ ë°˜ì‘í–ˆëŠ”ì§€ (ì¦‰, ê³ ê° íŠ¹ì„±ì— ë”°ë¥¸ ì„±ê³¼ ì°¨ì´ê°€ í°ì§€)

2. ì´ë¥¼ í†µí•´, **ì •ì±…ë³„ë¡œ ê³ ê° ë§ì¶¤í˜• ì„¤ê³„ê°€ í•„ìš”í•œì§€**, ë˜ëŠ” **ë²”ìš©ì (robust) ì •ì±…ì¸ì§€**ë¥¼ íŒë‹¨í•´ì£¼ì„¸ìš”.

3. ë§ˆì§€ë§‰ìœ¼ë¡œ, **ì •ì±…ë³„ íŠ¹ì„± ë°˜ì‘ í”„ë¡œíŒŒì¼ì„ ìš”ì•½**í•˜ì—¬  
   ì‹¤ì œ ìš´ì˜ ì‹œ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ì •ì±…ì„ ì„ íƒí•  ìˆ˜ ìˆì„ì§€ ì „ëµì ìœ¼ë¡œ í•´ì„í•´ì£¼ì„¸ìš”.
"""
RQ4_PROMPT = """
ë‹¤ìŒì€ ë™ì¼í•œ ì¶”ì²œ ì •ì±…(MF)ì— ëŒ€í•´ ë‹¤ì–‘í•œ ë¦¬ë­í‚¹ ì „ëµ(Prefer, Popularity, Diversity)ì„ ì ìš©í–ˆì„ ë•Œ
ê³ ê°ì˜ í˜ì´ì§€ íë¦„ ë° ìµœì¢… ì„ íƒ í–‰ë™ì— ëŒ€í•œ ì‹œê°í™” ë°ì´í„°ì…ë‹ˆë‹¤.

- ì²« ë²ˆì§¸ ê·¸ë˜í”„ëŠ” í˜ì´ì§€ë³„ ê³ ê° ì”ì¡´ ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
- ë‘ ë²ˆì§¸~ë„¤ ë²ˆì§¸ ê·¸ë˜í”„ëŠ” ê° í˜ì´ì§€ì—ì„œì˜ ê³ ê° í‰ê·  íŠ¹ì„±(activity, conformity, diversity) ë° ì„ íƒë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- ë§ˆì§€ë§‰ Sankey ë‹¤ì´ì–´ê·¸ë¨ì€ ê° í˜ì´ì§€ì—ì„œ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™í•˜ê±°ë‚˜ ìµœì¢… ì´íƒˆí•œ ê³ ê°ì˜ ë§Œì¡± ìˆ˜ì¤€(satisfied/unsatisfied)ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.

ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”:

1. **ê° ë¦¬ë­í‚¹ ì „ëµì´ ê³ ê°ì˜ ì´íƒˆë¥ ê³¼ ì„ íƒ í–‰ë™ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ì—ˆëŠ”ê°€?**
2. **ê³ ê° íŠ¹ì„±ì— ë”°ë¼ íŠ¹ì • ë¦¬ë­í‚¹ ì „ëµì´ ë” íš¨ê³¼ì ì¸ íë¦„ì„ ë§Œë“¤ì–´ë‚´ëŠ”ê°€?**
3. **íŠ¹ì • ë¦¬ë­í‚¹ ì „ëµì´ ë§Œì¡±ë„ ì¸¡ë©´ì—ì„œ ìœ ì˜ë¯¸í•œ upliftë¥¼ ë³´ì˜€ëŠ”ê°€?**
4. **ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‹œ ì–´ë–¤ ì „ëµì„ ì–´ë–¤ ê³ ê°êµ°ì— ì ìš©í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì¼ì§€ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ë³´ì„¸ìš”.**

ë¶„ì„ ê²°ê³¼ëŠ” ê°ê´€ì ì¸ ìˆ˜ì¹˜ì™€ ì¸ê³¼ì  í•´ì„ì„ í•¨ê»˜ í¬í•¨í•˜ê³ , ì „ë¬¸ê°€ ê´€ì ì—ì„œ ì „ëµì  ì œì–¸ í˜•íƒœë¡œ ë§ˆë¬´ë¦¬í•´ ì£¼ì„¸ìš”.
"""

def summarize_rq(prompt: str, str_summary: str, model="gpt-4o-mini-2024-07-18") -> str:
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¶”ì²œ ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¸ê³¼ì  ê´€ì ì—ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”."},
        {"role": "user", "content": prompt},
        {"role": "user", "content": f"ë¶„ì„ ê²°ê³¼ ë°ì´í„°:\n{str_summary}"}
    ]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0.4,
        max_tokens=800
    )
    return response['choices'][0]['message']['content']

SIM_AGENT_PROMPT = """
ë‹¤ìŒì€ ê³ ê°ë“¤ì˜ ì˜í™” ì·¨í–¥ì„ ì¡°ì‚¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
ë°ì´í„° AëŠ” í‚¤ì›Œë“œ ëª©ë¡ì´ê³ , ë°ì´í„° BëŠ” [avatar_id, taste, resaon]ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ë°ì´í„° Aì˜ í‚¤ì›Œë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° Bì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ì•„ë°”íƒ€ 1ê°œë¥¼ ì°¾ì•„ avatar_id ê°’ë§Œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€ ì˜ˆì‹œ: 1
ë‹µë³€ ì˜ˆì‹œ: 29
"""


def get_sim_agent(prompt: str, data_a: str, data_b: str, model="gpt-4o-mini-2024-07-18") -> str:
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¶”ì²œ ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ ìœ ì‚¬í•œ ì·¨í–¥ì„ ê°€ì§„ ì•„ë°”íƒ€ idë¥¼ ë‹µí•˜ì„¸ìš”."},
        {"role": "user", "content": prompt},
        {"role": "user", "content": f"ë°ì´í„° A í‚¤ì›Œë“œ:\n{data_a}"},
        {"role": "user", "content": f"ë°ì´í„° B avatar ë°ì´í„°:\n{data_b}"}
    ]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0.2,
        max_tokens=800
    )
    return response['choices'][0]['message']['content']



def summarize_rq1_overall(df):
    df_filtered = df[df["rerank"] == "Prefer"]
    summary = []
    for trait in ["activity", "conformity", "diversity"]:
        grouped = df_filtered.groupby([trait, "policy"])["satisfaction"].mean().unstack()
        baseline = grouped.mean(axis=1)
        delta = grouped.subtract(baseline, axis=0).round(3)
        delta.insert(0, "trait", delta.index)
        delta["type"] = trait
        summary.append(delta.reset_index(drop=True))
    result_df = pd.concat(summary)
    return result_df.to_markdown(index=False)

def summarize_rq2_overall(df):
    from itertools import combinations
    df_filtered = df[df["rerank"] == "Prefer"]
    uplift_data = []
    for trait in ["activity", "conformity", "diversity"]:
        for t_val in df[trait].unique():
            group = df_filtered[df[trait] == t_val]
            mean_satis = group.groupby("policy")["satisfaction"].mean()
            for p1, p2 in combinations(mean_satis.index, 2):
                diff = round(mean_satis[p1] - mean_satis[p2], 3)
                uplift_data.append((trait, t_val, f"{p1} vs {p2}", diff))
    uplift_df = pd.DataFrame(uplift_data, columns=["trait", "value", "policy_pair", "uplift"])
    return uplift_df.pivot(index=["trait", "value"], columns="policy_pair", values="uplift").to_markdown()

def summarize_rq3_overall(df):
    result = []
    for policy in df["policy"].unique():
        row = [policy]
        for trait in ["activity", "conformity", "diversity"]:
            group = df[(df["rerank"] == "Prefer") & (df["policy"] == policy)].groupby(trait)["satisfaction"].mean()
            group = group[[v for v in group.index if v not in ["ì¤‘ê°„", "ê· í˜•í˜•"]]]
            variation = round(group.max() - group.min(), 3) if not group.empty else 0
            row.append(variation)
        result.append(row)
    variation_df = pd.DataFrame(result, columns=["policy", "activity", "conformity", "diversity"])
    return variation_df.set_index("policy").to_markdown()

def summarize_rq4_overall(df):
    df_mf = df[df["policy"] == "MF"]
    result = []

    for rerank in df_mf["rerank"].unique():
        pages = df_mf[df_mf["rerank"] == rerank]["page"].value_counts().sort_index()
        total_exit = sum(df_mf[(df_mf["rerank"] == rerank) & (df_mf["page"] == pages.index.max())]["satisfaction_level"]
                         .apply(lambda x: x in ["satisfied", "unsatisfied"]))

        satisfied_exit = sum(df_mf[(df_mf["rerank"] == rerank) & (df_mf["page"] == pages.index.max())]["satisfaction_level"]
                             == "satisfied")

        result.append({
            "rerank": rerank,
            "total_customers": pages.iloc[0],
            "final_page": pages.index.max(),
            "final_page_customers": pages.iloc[-1],
            "satisfied_exit": satisfied_exit,
            "satisfaction_ratio": round(satisfied_exit / total_exit, 3) if total_exit > 0 else 0
        })

    return pd.DataFrame(result).to_markdown(index=False)


# -------

def prepare_page_funnel_by_rerank(df):
    result = []
    df_mf = df[df["policy"] == "MF"]
    for rerank in df_mf["rerank"].unique():
        for page in range(1, 6):
            subset = df_mf[(df_mf["rerank"] == rerank) & (df_mf["page"] == page)]
            if subset.empty:
                continue
            result.append({
                "rerank": rerank,
                "page": page,
                "count": len(subset)
            })
    return pd.DataFrame(result)

def prepare_trait_average_by_page(df, trait_name):
    df_mf = df[df["policy"] == "MF"]
    result = []
    for rerank in df_mf["rerank"].unique():
        for page in range(1, 6):
            subset = df_mf[(df_mf["rerank"] == rerank) & (df_mf["page"] == page)]
            if subset.empty:
                continue
            result.append({
                "rerank": rerank,
                "page": page,
                "trait": trait_name,
                "trait_avg": subset[trait_name].map({"ì ê²Œë´„":1, "ê°€ë”ë´„":2, "ìì£¼ë´„":3, "ë…ë¦½í˜•":1, "ê· í˜•í˜•":2, "ë™ì¡°í˜•":3, "ì·¨í–¥í˜•":1, "ê· í˜•í˜•":2, "ë‹¤ì–‘í˜•":3}).mean()
            })
    return pd.DataFrame(result)

def plot_funnel_customer_count_by_rerank(df):
    df_rerank = prepare_page_funnel_by_rerank(df)
    fig = px.bar(df_rerank, x="page", y="count", color="rerank", barmode="group",
                 title="Pageë³„ ê³ ê° ìˆ˜ (ë¦¬ë­í‚¹ë³„)")
    return fig

def plot_trait_line_over_pages(df, trait_name):
    trait_df = prepare_trait_average_by_page(df, trait_name)
    fig = px.line(trait_df, x="page", y="trait_avg", color="rerank", markers=True,
                  title=f"Pageë³„ {trait_name} í‰ê· ê°’ (ë¦¬ë­í‚¹ë³„)",
                  labels={"trait_avg": f"{trait_name} í‰ê· "})
    return fig


def plot_sankey_binary_exit(df):
    df_mf = df[df["policy"] == "MF"]
    rerank_list = df_mf["rerank"].unique().tolist()
    sankey_figs = []

    for rerank in rerank_list:
        sankey_data = []
        df_sub = df_mf[df_mf["rerank"] == rerank]
        for avatar_id, group in df_sub.groupby("avatar_id"):
            group = group.sort_values("page").reset_index(drop=True)
            pages = group["page"].tolist()
            rerank = group["rerank"].iloc[0]

            for i in range(len(pages)):
                curr = f"Page {pages[i]}"
                if i + 1 < len(pages):
                    nxt = f"Page {pages[i + 1]}"
                    sankey_data.append((curr, nxt))
                else:
                    rating_list = group.loc[i, "rating"]
                    select_rate = len(rating_list) / 4 if rating_list else 0
                    satis_bin = "satisfied" if select_rate >= 0.5 else "unsatisfied"
                    nxt = f"Exit: {satis_bin}"
                    sankey_data.append((curr, nxt))

        # ë…¸ë“œ ì„¤ì •
        labels = [f"Page {i}" for i in range(1, 6)] + ["Exit: satisfied", "Exit: unsatisfied"]
        label_idx = {label: i for i, label in enumerate(labels)}

        # ë§í¬ ì„¤ì •
        from collections import Counter
        links = Counter(sankey_data)
        source = [label_idx[s] for s, t in links]
        target = [label_idx[t] for s, t in links]
        value = [v for v in links.values()]

        # ê³ ì • ìœ„ì¹˜ ì„¤ì •
        x_pos = [0.1, 0.3, 0.5, 0.7, 0.9] + [1.0, 1.0]
        y_pos = [0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.3]  # ìœ„ìª½ ì •ë ¬

        fig = go.Figure(data=[go.Sankey(
            arrangement="snap",
            node=dict(
                pad=15,
                thickness=20,
                line=dict(color="black", width=0.5),
                label=labels,
                x=x_pos,
                y=y_pos
            ),
            link=dict(source=source, target=target, value=value)
        )])
        fig.update_layout(title=f"ğŸ“Š Sankey Diagram - {rerank} ì„ íƒë¥  ê¸°ë°˜ ë§Œì¡±ë„", font_size=10)
        
        sankey_figs.append(fig)

    return sankey_figs


def rerank_dashboard(df):
    # ë¦¬ë­í‚¹ë³„ í˜ì´ì§€ë‹¹ ê³ ê° ìˆ˜ ì‹œê°í™”
    fig1 = plot_funnel_customer_count_by_rerank(df)
    fig2 = plot_trait_line_over_pages(df, "activity")
    fig3 = plot_trait_line_over_pages(df, "conformity")
    fig4 = plot_trait_line_over_pages(df, "diversity")
    sankey_figs = plot_sankey_binary_exit(df)


    return fig1, fig2, fig3, fig4, sankey_figs




def customer_input_ui():
    gr.Markdown("## ğŸ¯ ê³ ê° íŠ¹ì„± ì„ íƒ")

    with gr.Row():
        activity = gr.Radio(
            ["ì ê²Œë´„", "ê°€ë”ë´„", "ìì£¼ë´„"],
            label="ì‹œì²­ í™œë™ëŸ‰ (Activity)"
        )
        conformity = gr.Radio(
            ["ë…ë¦½í˜•", "ê· í˜•í˜•", "ë™ì¡°í˜•"],
            label="ë™ì¡° ì„±í–¥ (Conformity)"
        )
        diversity = gr.Radio(
            ["ì·¨í–¥í˜•", "ê· í˜•í˜•", "ë‹¤ì–‘í˜•"],
            label="ë‹¤ì–‘ì„± ì„±í–¥ (Diversity)"
        )

    gr.Markdown("## ğŸ¿ ê´€ì‹¬ ì¥ë¥´ í‚¤ì›Œë“œ ì„ íƒ")
    taste_keywords = gr.CheckboxGroup(
        ["ë¡œë§¨ìŠ¤", "ì•¡ì…˜", "ë“œë¼ë§ˆ", "ê³µí¬", "SF", "ì½”ë¯¸ë””", "ìŠ¤ë¦´ëŸ¬", "íœ´ë¨¼ë“œë¼ë§ˆ"],
        label="ê´€ì‹¬ìˆëŠ” ì¥ë¥´/ë¶„ìœ„ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš” (1ê°œ ì´ìƒ)"
    )

    gr.Markdown("## âš™ï¸ ì¶”ì²œ ì„¤ì • ì„ íƒ")
    with gr.Row():
        policy = gr.Radio(
            ["MF", "MultiVAE", "Popular", "Random"],
            label="ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜"
        )
        rerank = gr.Radio(
            ["Prefer", "Popular", "Diversity"],
            label="ë¦¬ë­í‚¹ ë°©ì‹"
        )

    submit_btn = gr.Button("ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰í•˜ê¸°")

    return submit_btn, activity, conformity, diversity, taste_keywords, policy, rerank

def find_most_similar_avatar(policy, rerank, user_traits, taste_keywords, df_user):
    df_candi = df_user[(df_user.activity==user_traits['activity'])& (df_user.conformity==user_traits['conformity']) & (df_user.diversity==user_traits['diversity'])]
    if len(df_candi):
        try: 
            sim_id = get_sim_agent(SIM_AGENT_PROMPT, taste_keywords, df_candi[['avatar_id','taste','reason']].to_markdown(index=False))
            return int(sim_id)
        except:
            return -1
    else:
        return -1 # ì·¨í–¥ ì¡°í•© ì—†ìŒ
    return -1
def parse_agent_log(log_str):
    """
    ë¡œê·¸ë¥¼ 'í˜ì´ì§€', 'ì‘ë‹µ', 'ì¸í„°ë·°' ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ  ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    lines = log_str.strip().split("\n")
    sections = []
    current_section = []
    section_title = "ğŸ“ ë¡œê·¸ ì‹œì‘"

    def flush_section():
        nonlocal current_section, section_title
        if current_section:
            content = f"#### {section_title}\n\n" + "\n".join(current_section)
            sections.append(content)
        current_section = []

    for line in lines:
        line = line.strip()

        if "Recommendation Page" in line:
            flush_section()
            section_title = f"ğŸ“„ {line.strip('= ').strip()}"
        elif "Response" in line:
            flush_section()
            section_title = f"ğŸ¯ {line.strip('= ').strip()}"
        elif "interview" in line.lower() or "RATING:" in line:
            flush_section()
            section_title = "ğŸ—£ï¸ ì¸í„°ë·°"
        elif line.startswith("POSITIVE:") or line.startswith("NEGATIVE:") or line.startswith("[EXIT]") or line.startswith("[NEXT]"):
            current_section.append(f"**{line}**")
        else:
            current_section.append(line)

    flush_section()
    return sections



def page1_agent4rec_ui(df,df_user, df_log, policy_list):
    with gr.Tabs():
        with gr.Tab("0ï¸âƒ£ Agent4Rec ë° ë°ëª¨ ì†Œê°œ"):

            gr.Image("./assets/agent4rec_main.png", show_label=False, container=False, height=350)
            gr.Markdown("""
            ## â„¹ï¸ ì¶”ì²œ ì‹œë®¬ë ˆì´ì…˜ ë°ëª¨ ì†Œê°œ
            
            ì´ ë°ëª¨ëŠ” **ê³ ê° í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ Agent**ë¥¼ í™œìš©í•œ ì¶”ì²œ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´,  
            ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ë° ë¦¬ë­í‚¹ ì •ì±…ì´ **ê³ ê° íŠ¹ì„±ê³¼ ì–´ë–»ê²Œ ìƒí˜¸ì‘ìš©í•˜ë©° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€** ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

            íŠ¹íˆ ì‹¤ì œ A/B í…ŒìŠ¤íŠ¸ê°€ ì–´ë ¤ìš´ í™˜ê²½ì—ì„œë„,  
            **ì •ì±…ë§Œ ë‹¤ë¥´ê²Œ ì ìš©í•œ ë°˜ì‚¬ì‹¤ì  ì‹œë‚˜ë¦¬ì˜¤(Counterfactual Setup)** ë¥¼ í†µí•´  
            **ì •ì±… íš¨ê³¼(Policy Effect)ì˜ ì¸ê³¼ì  í•´ì„(Causal Interpretation)** ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
            
            ### ğŸ§ª ì‹œë®¬ë ˆì´ì…˜ ì‹¤í—˜ì˜ ì¸ê³¼ì  êµ¬ì¡°

            - ë™ì¼í•œ ê³ ê°êµ°ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ì¶”ì²œ ì •ì±…(policy)ê³¼ ë¦¬ë­í‚¹ ì „ëµ(rerank)ì„ ì ìš©
            - ì´ë¥¼ í†µí•´ **ì •ì±…ì´ ì—†ì—ˆì„ ê²½ìš°ì™€ ìˆì—ˆì„ ê²½ìš°ì˜ ì°¨ì´(uplift)** ë¥¼ ì¶”ì •
            - ê³ ê°ì˜ íŠ¹ì„±(activity, conformity, diversity)ì„ ê¸°ë°˜ìœ¼ë¡œ **ì´ì§ˆì  íš¨ê³¼(Heterogeneous Treatment Effect, HTE)** ë¶„ì„ ê°€ëŠ¥   
            
            ### ğŸ“Š ë°ëª¨ êµ¬ì„±

            1. **ì •ì±… íš¨ê³¼ ë¶„ì„ (RQ1â€“3)**  
            > "*ì •ì±…ì— ë”°ë¼ ê³ ê°ì˜ ë°˜ì‘ì´ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ê³  ì–´ë–¤ ì •ì±…ì´ ë” íš¨ê³¼ì ì¸ê°€?"  
            ë™ì¼ ê³ ê°êµ°ì„ ëŒ€ìƒìœ¼ë¡œ ë‹¤ì–‘í•œ ì¶”ì²œì •ì±…ì„ ì ìš©í•œ í›„ **ë§Œì¡±ë„ ë° ì„ íƒë¥  ì°¨ì´(uplift)** ë¶„ì„

            2. **ë¦¬ë­í‚¹ í¼ë„ ë¶„ì„ (RQ4)**  
            > "ë¦¬ë­í‚¹ ì „ëµì´ ê³ ê° ì´íƒˆë¥  ë° í˜ì´ì§€ ì´ë™ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ê°€?"  
            ê° í˜ì´ì§€ë³„ ì´íƒˆë¥ ê³¼ ë§Œì¡±ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³ ê° íë¦„ì„ **í¼ë„ êµ¬ì¡°ë¡œ ì‹œê°í™”**

            3. **ì‹œë®¬ë ˆì´ì…˜ ì‹œì—°**  
            > ê³ ê° íŠ¹ì„±ì„ ì§ì ‘ ì„¤ì •í•˜ì—¬ ì¶”ì²œ íë¦„ì„ ì²´í—˜  
            ì‹¤ì œ ê³ ê°ê³¼ ìœ ì‚¬í•œ Agentë¥¼ í†µí•´ **ê°œì¸í™”ëœ ì¶”ì²œ ì‹œë‚˜ë¦¬ì˜¤ì˜ íë¦„ê³¼ ê²°ê³¼ë¥¼ í™•ì¸** 
            
            ### ğŸš€ ê¸°ì¡´ Agent4Rec ëŒ€ë¹„ ê°œì„  ì‚¬í•­
            
            ê¸°ì¡´ ì‹œë®¬ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ë¥¼ í™•ì¥í•˜ì—¬ ë”ìš± ì •êµí•œ ê³ ê° Agentë¥¼ êµ¬ì¶•í•˜ì˜€ê³ , 
            ì‹¤ì œ ì„œë¹„ìŠ¤ ì •ì±…ì— ë”°ë¥¸ ì„±ê³¼(uplift)ì˜ ì¸ê³¼ì  ë¶„ì„ì„ í†µí•´ ì •êµí•œ ì •ì±… ë¹„êµì™€ ì„¤ëª…ì´ ê°€ëŠ¥í•˜ë„ë¡ ê°œì„ í–ˆìŠµë‹ˆë‹¤.
            - ê³ ê° íŠ¹ì„±(í™œë™ì„±/ë™ì¡°ì„±/ë‹¤ì–‘ì„±) ì¶”ì •ì¹˜ë¥¼ í™•ë¥ ê°’ìœ¼ë¡œ ì§ì ‘ ë°˜ì˜í•´ Agentì˜ ì„ íƒ í–‰ë™ì´ ì‹¤ì œ ë¡œê·¸ì— ë” ìœ ì‚¬í•´ì¡Œìœ¼ë©°, ì‹œë®¬ë ˆì´ì…˜ ë‚´ í‰ê·  ì„ íƒë¥ (CTR)ì´ ê¸°ì¡´ ëŒ€ë¹„ 55% ì¦ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.
            - ì‹¤ì œ ì„œë¹„ìŠ¤ í™˜ê²½ì„ ê³ ë ¤í•œ **ë¦¬ë­í‚¹ ë°©ì‹(policy reranking)** ì ìš© ë° ë¹„êµ ì‹¤í—˜ ì§„í–‰ (ì¸ê¸°ë„, ë‹¤ì–‘ì„± ë¦¬ë­í‚¹ ì¶”ê°€, ê°€ê²©ìˆœ ë¦¬ë­í‚¹ í™•ì¥ ê°€ëŠ¥)
              - ì´ 12ê°œ ì‹¤í—˜ ì¡°í•©: `4ê°œ ì¶”ì²œ ì •ì±…` Ã— `3ê°œ ë¦¬ë­í‚¹ ë°©ì‹`
            
            ### ğŸ§¬ ì‹¤í—˜ ìš”ì•½

            - **ê³ ê° ìˆ˜**: ì´ 300ëª… (ê³ ê° ì•„ë°”íƒ€ ê¸°ë°˜)
            - **ê³ ê° íŠ¹ì„±**: ì„¸ ê°€ì§€ Trait
              - `activity`: ì‹œì²­ ë¹ˆë„
              - `conformity`: ì¸ê¸° ì½˜í…ì¸ ì— ëŒ€í•œ ë™ì¡° ì •ë„
              - `diversity`: ì·¨í–¥ ë‹¤ì–‘ì„±
            - **ì‹¤í—˜**
              - ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜(`policy`) Ã— ë¦¬ë­í‚¹ ì „ëµ(`rerank`) ì¡°í•© ì‹¤í—˜
                - MF, VAE, Pop, Random
                - Preference, Popularity, Diversity
            - **ì˜¨ë¼ì¸(ì‹œë®¬ë ˆì´ì…˜) ì„±ê³¼ ì§€í‘œ**
              - ë§Œì¡±ë„(`satisfaction`), ì„ íƒë¥ (`select_rate`), í˜ì´ì§€ ì´íƒˆë¥  ë“±
            - **ë°ì´í„° í¬ì¸íŠ¸**
              - `avatar_id`: ì•„ë°”íƒ€ ID
              - `taste`: ê³ ê°ì˜ ì·¨í–¥ ì„¤ëª…
              - `page`: ì¶”ì²œ í˜ì´ì§€ (1~5ë‹¨ê³„)
              - `recommended`: ì¶”ì²œëœ ì˜í™” ë¦¬ìŠ¤íŠ¸
              - `watched`: ì‹¤ì œë¡œ ë³¸ ì˜í™”
              - `rating`: ê° ì˜í™”ì— ëŒ€í•œ í‰ì  ë¦¬ìŠ¤íŠ¸
              - `feeling`: ì˜í™”ë³„ ì‹œì²­ í›„ ì†Œê° (ìì—°ì–´)
              - `ground_truth`: ì¶”ì²œ í›„ë³´ ë‚´ ì„ í˜¸ ì˜í™” ì—¬ë¶€

            ### ğŸ”¬ ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ì— ëŒ€í•œ ì‹ ë¢°ì„±

            ì´ ë°ëª¨ëŠ” ìµœì‹  ì¶”ì²œ ì‹œìŠ¤í…œ ì—°êµ¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” [On Generative Agents in Recommendation (SIGIR 2024)](https://dl.acm.org/doi/abs/10.1145/3626772.3657844) êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
            Agent ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ì€ ì‹¤ì œ ì‚¬ìš©ì ë¡œê·¸ì™€ì˜ ìœ ì‚¬ë„ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ ì…ì¦í•˜ë©°, ë‹¤ì–‘í•œ ì—°êµ¬ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ í‰ê°€ë¥¼ í†µí•´ **ì‹œë®¬ë ˆì´ì…˜ì˜ ì‹ ë¢°ì„±**ì„ í™•ë³´í•˜ì˜€ìŠµë‹ˆë‹¤:

            - âœ… **í–‰ë™ ì§€í‘œ ê¸°ë°˜ ìœ ì‚¬ë„ í‰ê°€**  
              - Agentì˜ ì„ íƒë¥  (Click-through rate), ì´íƒˆë¥  (Exit rate), ë§Œì¡±ë„ (Rating) ë“±ì€ ì‹¤ì œ ë¡œê·¸ì™€ ìœ ì‚¬í•˜ê²Œ ì¬í˜„ë©ë‹ˆë‹¤.

            - âœ… **ì„ í˜¸ë„ ì •ë ¬ ì •í™•ë„ (Preference Alignment Accuracy)**
              - **ì•½ 65%**ì˜ ì •í™•ë„ë¡œ ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì¢‹ì•„í•  ë§Œí•œ ì•„ì´í…œì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.
              - **ì•½ 75%**ì˜ Recall: ì‚¬ìš©ìì˜ ì§„ì§œ ê´€ì‹¬ì‚¬ë¥¼ ìƒë‹¹ ìˆ˜ì¤€ ë°˜ì˜í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

            - âœ… **ì‹¤ì œ ê³ ê° ì·¨í–¥ íŠ¹ì„±ì˜ ë³´ì¡´**
              - AgentëŠ” ì‹¤ì œ ê³ ê°ì˜ **ì‹œì²­ ë¹ˆë„(Activity)**, **ì¸ê¸°ë„ ë¯¼ê°ë„(Conformity)**, **ë‹¤ì–‘ì„± ì„±í–¥(Diversity)**ì„ ë°˜ì˜í•˜ì—¬ ë‹¨ìˆœ ì‘í’ˆ ì„ í˜¸ë„ë¿ë§Œ ì•„ë‹ˆë¼ ê³ ê° í–‰ë™ íŠ¹ì„±ë„ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.
              - ì‹œë®¬ë ˆì´ì…˜ ëŒ€ìƒ ê³ ê° ì§‘ë‹¨ì€ ì‹¤ì œ ì‚¬ìš©ì ë¶„í¬ì™€ **í†µê³„ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì·¨í–¥ íŠ¹ì„± êµ¬ì¡°**ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

            - ğŸ“š **ê´€ë ¨ ì—°êµ¬ ì‚¬ë¡€**
              - [CausalSim (NSDI 2023)](https://www.usenix.org/biblio-13301): Agent ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ì„ í™œìš©í•˜ì—¬ causal effect ì¸¡ì •ì´ ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ì™€ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§
            ---                        
            ## Agent4Rec Architecture
            """)
            
            gr.Image("./assets/agent4rec_flow.png", show_label=False, container=False, height=400)
            gr.Markdown("""
            ### ğŸ§  ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìš”ì•½

            ì¶”ì²œ ì‹œë®¬ë ˆì´ì…˜ì€ **ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(Agent Architecture)**ê³¼ **ì¶”ì²œ í™˜ê²½(Recommendation Environment)** ë‘ êµ¬ì„±ìœ¼ë¡œ ë‚˜ë‰˜ë©°, ì‹¤ì œ ì‚¬ìš©ìì™€ ìœ ì‚¬í•œ ìƒí˜¸ì‘ìš©ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•œ êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

            #### ğŸ”´ Agent Architecture

            - **ğŸ“Œ í”„ë¡œí•„ ëª¨ë“ˆ (Profile Module)**  
              - ì‚¬ìš©ìì˜ ì‹œì²­ ì´ë ¥ ë° í‰ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ìœ í•œ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ì—¬ í”„ë¡œí•„ ìƒì„±  
              - ì •ì˜ëœ ì„¸ ê°€ì§€ ì‚¬íšŒì  íŠ¹ì„±:
                  - `activity`: ì–¼ë§ˆë‚˜ ìì£¼ ì½˜í…ì¸ ë¥¼ ì†Œë¹„í•˜ëŠ”ê°€  
                  - `conformity`: ëŒ€ì¤‘ì  ì˜ê²¬ê³¼ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œê°€  
                  - `diversity`: ì–¼ë§ˆë‚˜ ë‹¤ì–‘í•œ ì½˜í…ì¸ ë¥¼ ì†Œë¹„í•˜ëŠ”ê°€  

            - **ğŸ§  ë©”ëª¨ë¦¬ ëª¨ë“ˆ (Memory Module)**  
              - ì‚¬ìš©ì í–‰ë™ì„ ê¸°ì–µìœ¼ë¡œ ì €ì¥í•˜ì—¬ ë‹¤ìŒ í–‰ë™ì— ë°˜ì˜
                  - `ì‚¬ì‹¤ì  ê¸°ì–µ`: ì‹œì²­/í‰ê°€ ë“± êµ¬ì²´ì ì¸ ìƒí˜¸ì‘ìš© ì´ë ¥  
                  - `ê°ì •ì  ê¸°ì–µ`: ë§Œì¡±ë„, í”¼ë¡œê° ë“± ì •ì„œì  ë°˜ì‘
              - ìì—°ì–´ ë° ë²¡í„° ì„ë² ë”© í˜•íƒœë¡œ ì €ì¥, ê²€ìƒ‰, ë°˜ì˜ ê°€ëŠ¥

            - **ğŸ¤– í–‰ë™ ëª¨ë“ˆ (Action Module)**  
              - í”„ë¡œí•„ ê¸°ë°˜ ì‹œì²­ ë° í‰ê°€  
              - ê°ì • ê¸°ë°˜ ì´íƒˆ/ë§Œì¡±ë„ í‰ê°€ ë° ì¸í„°ë·° ìˆ˜í–‰  

            #### ğŸ”µ Recommendation Environment

            - **ğŸ¬ ì•„ì´í…œ í”„ë¡œí•„ ìƒì„±**  
              - ì•„ì´í…œì˜ í’ˆì§ˆ, ì¸ê¸°ë„, ì¥ë¥´, ì¤„ê±°ë¦¬ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ í›„ë³´ êµ¬ì„±  
              - LLMì„ í™œìš©í•œ ì¥ë¥´ ìƒì„± ë° ê²€ì¦ì„ í†µí•´ ì‹ ë¢°ë„ í™•ë³´

            - **ğŸ“„ í˜ì´ì§€ ê¸°ë°˜ ì¶”ì²œ êµ¬ì¡°**  
              - ì‹¤ì œ ì„œë¹„ìŠ¤ì²˜ëŸ¼ **í˜ì´ì§€ ë‹¨ìœ„**ë¡œ ì¶”ì²œ ì œì‹œ  
              - ê° í˜ì´ì§€ì—ì„œ ìƒí˜¸ì‘ìš© í›„, ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ì–´ì§€ê±°ë‚˜ ì´íƒˆ ì—¬ë¶€ íŒë‹¨

            - **ğŸ§ª ë‹¤ì–‘í•œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì‹¤í—˜ ì§€ì›**  
              - `Random`, `Most Popular`, `MF`, `LightGCN`, `MultVAE` ë“± ë‹¤ì–‘í•œ ì •ì±… ë‚´ì¥  
              - ì™¸ë¶€ ì¶”ì²œ ëª¨ë¸ì„ ì‰½ê²Œ ì—°ë™í•  ìˆ˜ ìˆëŠ” í™•ì¥ êµ¬ì¡° ì œê³µ
            """)
        with gr.Tab("1ï¸âƒ£ ì •ì±… íš¨ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"):
            gr.Markdown("""
            ## ğŸ“Š ì •ì±… íš¨ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ

            ë³¸ ëŒ€ì‹œë³´ë“œëŠ” ì¶”ì²œ ì •ì±…ì´ ê³ ê° íŠ¹ì„±ê³¼ ì–´ë–»ê²Œ ìƒí˜¸ì‘ìš©í•˜ëŠ”ì§€ë¥¼ **ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ì¸ê³¼ì  ë¹„êµ** ë°©ì‹ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.  
            ë™ì¼í•œ ê³ ê° ì§‘ë‹¨ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì •ì±…ì„ ì ìš©í•˜ê³  ê·¸ ë°˜ì‘ì„ ë¹„êµí•¨ìœ¼ë¡œì¨, ë§ˆì¹˜ A/B í…ŒìŠ¤íŠ¸ì²˜ëŸ¼ **ì •ì±… ê°„ íš¨ê³¼(uplift)**ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

            ì‹¤í—˜ì€ ì•„ë˜ ì„¸ ê°€ì§€ ì¸ê³¼ì  ì§ˆë¬¸(RQ)ì— ê¸°ë°˜í•©ë‹ˆë‹¤:
            """)

            gr.Markdown("### ğŸ”¹ RQ1. ì •ì±…ë³„ ë§Œì¡±ë„ ì°¨ì´ (ê³ ê° íŠ¹ì„±ë³„)")
            gr.Markdown("- ì§ˆë¬¸: ì •ì±…ë§ˆë‹¤ ê³ ê° íŠ¹ì„±ì— ë”°ë¼ ë§Œì¡±ë„ê°€ ì–¼ë§ˆë‚˜ ë‹¬ë¼ì§€ëŠ”ê°€?")
            gr.Markdown("- ë¶„ì„: Violin + Scatter plotì„ í†µí•´ ë§Œì¡±ë„ ì¦ê° ë° ì„ íƒë¥ ì„ ë¹„êµí•©ë‹ˆë‹¤.")
            for trait in ["activity", "conformity", "diversity"]:
                gr.Markdown(f"#### â–¸ {trait} ê¸°ì¤€")
                v, s = plot_policy_by_trait(df, trait)
                gr.Plot(value=v)
                gr.Plot(value=s)

            with gr.Accordion("ğŸ“Œ Causal Interpretation Agent ê²°ê³¼ ìš”ì•½", open=False):
                summary_button = gr.Button("ìš”ì•½ ì‹¤í–‰")
                summary_output = gr.Markdown("â–¶ï¸ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ ìš”ì•½ì„ í™•ì¸í•˜ì„¸ìš”.")

                def run_summary_rq():
                    summary_data = summarize_rq1_overall(df)  # ê¸°ì¡´ í•¨ìˆ˜
                    return summarize_rq(RQ1_PROMPT, summary_data)  # GPT API í˜¸ì¶œ (ë˜ëŠ” ìš”ì•½ í•¨ìˆ˜)

                summary_button.click(fn=run_summary_rq, inputs=[], outputs=summary_output)

            gr.Markdown("### ğŸ”¹ RQ2. ì •ì±… ê°„ uplift ë¹„êµ")
            gr.Markdown("- ì§ˆë¬¸: íŠ¹ì • ê³ ê° ê·¸ë£¹ì—ì„œ ì–´ë–¤ ì •ì±…ì´ ë” íš¨ê³¼ì ì¸ê°€?")
            gr.Markdown("- ë¶„ì„: ê° trait ê°’ë³„ë¡œ ì •ì±… ê°„ uplift ì°¨ì´ë¥¼ Bar chartë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.")
            for trait in ["activity", "conformity", "diversity"]:
                gr.Markdown(f"#### â–¸ {trait} ê¸°ì¤€")
                bar, = plot_uplift_by_trait(df, trait)
                gr.Plot(value=bar)
            
            with gr.Accordion("ğŸ“Œ Causal Interpretation Agent ê²°ê³¼ ìš”ì•½", open=False):
                summary_button = gr.Button("ìš”ì•½ ì‹¤í–‰")
                summary_output = gr.Markdown("â–¶ï¸ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ ìš”ì•½ì„ í™•ì¸í•˜ì„¸ìš”.")

                def run_summary_rq():
                    summary_data = summarize_rq2_overall(df)  # ê¸°ì¡´ í•¨ìˆ˜
                    return summarize_rq(RQ2_PROMPT, summary_data)  # GPT API í˜¸ì¶œ (ë˜ëŠ” ìš”ì•½ í•¨ìˆ˜)

                summary_button.click(fn=run_summary_rq, inputs=[], outputs=summary_output)



            gr.Markdown("### ğŸ”¹ RQ3. ì •ì±…ì˜ ë¯¼ê°ë„ ì°¨ì´")
            gr.Markdown("- ì§ˆë¬¸: ì–´ë–¤ ì •ì±…ì´ ê³ ê° íŠ¹ì„±ì— ë” ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ëŠ”ê°€?")
            gr.Markdown("- ë¶„ì„: Radar chartë¥¼ í†µí•´ ê° ì •ì±…ë³„ë¡œ trait í¸ì°¨ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
            radar = plot_policy_variation_radar(df)
            gr.Plot(value=radar)

            
            with gr.Accordion("ğŸ“Œ Causal Interpretation Agent ê²°ê³¼ ìš”ì•½", open=False):
                summary_button = gr.Button("ìš”ì•½ ì‹¤í–‰")
                summary_output = gr.Markdown("â–¶ï¸ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ ìš”ì•½ì„ í™•ì¸í•˜ì„¸ìš”.")

                def run_summary_rq():
                    summary_data = summarize_rq3_overall(df)  # ê¸°ì¡´ í•¨ìˆ˜
                    return summarize_rq(RQ3_PROMPT, summary_data)  # GPT API í˜¸ì¶œ (ë˜ëŠ” ìš”ì•½ í•¨ìˆ˜)

                summary_button.click(fn=run_summary_rq, inputs=[], outputs=summary_output)

            
        with gr.Tab("2ï¸âƒ£ ë¦¬ë­í‚¹ í¼ë„ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"):
            gr.Markdown("""
            ğŸ”„ ë¦¬ë­í‚¹ íš¨ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
            ë³¸ ëŒ€ì‹œë³´ë“œëŠ” ë¦¬ë­í‚¹ ì „ëµì´ ê³ ê° í–‰ë™ê³¼ ë§Œì¡±ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ì¸ê³¼ì  ë¹„êµ ë°©ì‹ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
            í•˜ë‚˜ì˜ ë™ì¼í•œ ì¶”ì²œ ì •ì±…(MF)ì„ ê³ ì •í•œ ìƒíƒœì—ì„œ ë‹¤ì–‘í•œ ë¦¬ë­í‚¹ ë°©ì‹ì„ ì ìš©í•˜ê³  ê³ ê°ì˜ íë¦„(í˜ì´ì§€ ì´ë™, ì„ íƒë¥ , ì´íƒˆ ë“±)ì„ ë¹„êµí•¨ìœ¼ë¡œì¨,
            ë§ˆì¹˜ A/B í…ŒìŠ¤íŠ¸ì²˜ëŸ¼ **ë¦¬ë­í‚¹ ì „ëµ ê°„ íš¨ê³¼(uplift)**ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

            ğŸ”¹ RQ4. ë¦¬ë­í‚¹ ì „ëµë³„ í¼ë„ íë¦„ ì°¨ì´
            - ì§ˆë¬¸: ë¦¬ë­í‚¹ ì „ëµì€ ê³ ê°ì˜ ì¶”ì²œ íë¦„(í˜ì´ì§€ ì´ë™/ì´íƒˆ/ë§Œì¡±ë„)ì— ì–´ë–¤ ì¸ê³¼ì  ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€?
            - ë¶„ì„:
              - í˜ì´ì§€ë³„ ê³ ê° ì”ì¡´ ìˆ˜ ì‹œê°í™” (Barplot)
              - ê³ ê° íŠ¹ì„±(í™œë™ì„±/ë™ì¡°ì„±/ë‹¤ì–‘ì„±)ì˜ í˜ì´ì§€ë³„ í‰ê·  ë³€í™” (Line + Barplot)
              - ìµœì¢… ì´íƒˆ ì‹œì ì˜ ë§Œì¡±ë„ íë¦„ì„ ë‚˜íƒ€ë‚´ëŠ” Sankey Diagram
            """)



            fig1, fig2, fig3, fig4, sankey_figs = rerank_dashboard(df)
            gr.Plot(value=fig1)
            gr.Plot(value=fig2)
            gr.Plot(value=fig3)
            gr.Plot(value=fig4)
            for fig in sankey_figs:
                gr.Plot(value=fig)



            
            with gr.Accordion("ğŸ“Œ Causal Interpretation Agent ê²°ê³¼ ìš”ì•½", open=False):
                summary_button = gr.Button("ìš”ì•½ ì‹¤í–‰")
                summary_output = gr.Markdown("â–¶ï¸ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ ìš”ì•½ì„ í™•ì¸í•˜ì„¸ìš”.")

                def run_summary_rq():
                    summary_data = summarize_rq4_overall(df)  # ê¸°ì¡´ í•¨ìˆ˜
                    return summarize_rq(RQ4_PROMPT, summary_data)  # GPT API í˜¸ì¶œ (ë˜ëŠ” ìš”ì•½ í•¨ìˆ˜)

                summary_button.click(fn=run_summary_rq, inputs=[], outputs=summary_output)


        with gr.Tab("3ï¸âƒ£ Trait ê¸°ë°˜ ì‚¬ìš©ì ì²´í—˜"):
            submit_btn, activity, conformity, diversity, taste_keywords, policy, rerank = customer_input_ui()

            def run_simulation(activity, conformity, diversity, taste_keywords, policy, rerank):
                user_traits = {
                    "activity": activity,
                    "conformity": conformity,
                    "diversity": diversity
                }
                avatar_id = find_most_similar_avatar(policy, rerank, user_traits, taste_keywords, df_user)

                if avatar_id < 0:
                    updates = [gr.update(visible=False) for _ in range(5)]
                    return ("ğŸ˜¢ ì…ë ¥í•œ ê³ ê° íŠ¹ì„±ê³¼ ë™ì¼í•œ ì•„ë°”íƒ€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", *updates)

                log_df = df_log[
                    (df_log.avatar_id == avatar_id) &
                    (df_log.rerank == rerank) &
                    (df_log.policy == policy)
                ]

                if len(log_df) == 0:
                    return f"ğŸ¯ ìœ ì‚¬ avatar ID: {avatar_id}", *[gr.update(visible=False) for _ in range(5)]

                log_str = log_df.iloc[0]["log"]
                parsed_sections = parse_agent_log(log_str)

                summary = f"ğŸ¯ ìœ ì‚¬ avatar ID: {avatar_id}\nğŸ“Œ ì¶”ì²œ ì •ì±…: {policy} / ë¦¬ë­í‚¹: {rerank}"
                outputs = []
                for i in range(5):
                    if i < len(parsed_sections):
                        outputs.append(gr.update(value=parsed_sections[i], visible=True))
                    else:
                        outputs.append(gr.update(visible=False))

                return summary, *outputs

            output_summary = gr.Markdown(label="ğŸ§  ê²°ê³¼ ìš”ì•½")
    
            # ìµœëŒ€ 5ê°œ ì„¹ì…˜ë§Œ ì˜ˆì‹œë¡œ ë§Œë“ ë‹¤ê³  ê°€ì •
            output_log1 = gr.Markdown(visible=False)
            output_log2 = gr.Markdown(visible=False)
            output_log3 = gr.Markdown(visible=False)
            output_log4 = gr.Markdown(visible=False)
            output_log5 = gr.Markdown(visible=False)
            
            log_outputs = [output_log1, output_log2, output_log3, output_log4, output_log5]
            submit_btn.click(
                fn=run_simulation,
                inputs=[activity, conformity, diversity, taste_keywords, policy, rerank],
                outputs=[output_summary] + log_outputs
            )


